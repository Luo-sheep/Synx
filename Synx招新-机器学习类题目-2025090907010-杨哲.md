# 一、Python 基础语法

# 一、命名

## 1. 变量命名规则

- 使用小写字母，可用下划线分隔（snake_case）,
- 命名清晰易懂，避免使用单字母（可能会和关键字）或无意义名称

**示例**：

- `student_score`
- `total_price`

## 2. 函数命名规则

- 同样使用小写字母加下划线（snake_case）
- 直观体现功能或行为

**示例**：

- `calculate_average()`
- `name_person()`

## 3. 类命名规则

- 使用首字母大写的驼峰式命名
- 类名应为名词，表示实体或抽象概念

**示例**：

- `StudentNumber`
- `IdentityNumber`

# 二、数据容器

## 1. 列表（list）

列表是 Python 中最常用的数据容器之一，适合存储有序、可变的数据集合。

### 特点：

- 元素有顺序，可以通过索引访问。

- 可以包含任意类型的数据，包括嵌套列表。

- 支持重复元素。

- 可以修改、添加、删除元素。

### 常见操作函数：

- append(x)：在末尾添加元素。

- pop(i)：移除并返回指定位置的元素。

- sort()：对列表进行排序。

- len()：获取列表长度。

- for item in list：遍历列表。

## 2. 元组（tuple）

元组是不可变的有序容器，适合存储固定结构的数据。

### 特点：

- 元素有顺序，但不能修改。

- 支持嵌套和多值返回。

- 占用内存比列表少，适合轻量级数据。

### 常见操作函数：

- len()：获取元组长度。

- count(x)：统计某个元素出现次数。

- index(x)：获取某个元素的索引。

- 支持解包：a, b = (1, 2)

### 页面应用场景：

- 表示坐标点 (x, y)。

- 函数返回多个值时使用元组封装。

## 3. 字典（dict）

字典是键值对结构的容器，适合存储映射关系。

### 特点：

- 无序（Python 3.7+ 保持插入顺序）。

- 每个键必须唯一，值可以重复。

- 可变，支持动态添加和修改。

### 常见操作函数：

get(key)：安全获取键对应的值。

keys() / values() / items()：遍历字典结构。

update()：批量更新键值对。

del dict[key]：删除指定键。

### 页面应用场景：

存储学生成绩：{"语文": 85, "数学": 92}

封装类中的私有属性 __scores。

## 4. 集合（set）

集合是无序且元素唯一的容器，适合去重和集合运算。

### 特点：

元素不重复。

无索引，不能通过位置访问。

支持集合运算（交集、并集、差集）。

### 常见操作函数：

add(x)：添加元素。

remove(x)：删除元素。

union(set2)：并集。

intersection(set2)：交集。

len()：获取集合大小。

### 页面应用场景：

去重学生姓名或科目。

分析标签或分类集合。

## 5. 字符串（str）

字符串是字符序列，虽然不是典型的容器，但在 Python 中也支持很多容器操作。

### 特点：

有序、不可变。

支持索引和切片。

常用于文本处理。

### 常见操作函数：

split()：按分隔符拆分字符串。

join()：将列表拼接成字符串。

replace()：替换子串。

find() / index()：查找子串位置。

### 页面应用场景：

构造输出语句：print(f"{name}: 总分={total}")

处理学生姓名、成绩描述。

# 二、面向对象编程

## 1.类与对象

类（Class）是抽象模板，用于定义某类事物的属性和行为。

对象（Object）是类的具体实例，拥有独立的数据但共享类定义的结构。

关系：类是蓝图，对象是根据蓝图构建的实体。多个对象可以由同一个类创建。

## 3.继承

允许一个类（称为子类 / 派生类）复用另一个类（称为父类 / 基类）的属性和方法，同时还能扩展或修改父类的功能。

好处：
代码复用：子类继承父类功能

结构清晰：按层次组织功能

支持扩展：子类可新增或重写方法

## 4.多态

指的是不同类的对象对同一方法调用，会产生不同的执行结果。

“同一件事，不同对象做起来有不同的表现”。

## 5.迭代器

1. 可迭代对象（Iterable）

能产生迭代器的对象，即可以被for循环遍历的对象。常见的可迭代对象包括：

内置序列：列表、元组、字符串、集合、字典（键的集合）；
自定义类：实现了__iter__()方法（返回迭代器），或实现__getitem__()方法且索引从 0 开始（Python 的 “鸭子类型” 兼容）。

本质：可迭代对象是 “数据源”，它本身不直接存储遍历状态，而是通过生成迭代器来完成遍历。

2. 迭代器（Iterator）

能记住遍历位置的对象，用于逐个返回序列中的元素。它必须实现两个方法：

__iter__()：返回自身（确保迭代器也能被for循环处理）；
__next__()：返回下一个元素，若没有更多元素则抛出StopIteration异常。

本质：迭代器是 “遍历工具”，它持有当前遍历的状态（如当前位置），每次调用next()都会前进一位。

# 三、梯度下降

## 1.平方和损失函数（Sum of Squared Errors, SSE）

是衡量模型预测值与真实值之间差距的常用指标

它衡量的是所有样本预测误差的平方和，越小表示模型越准确。

在机器学习中的作用：

作为目标函数，指导模型参数的优化方向。

在回归任务中广泛使用，尤其是一元线性回归。

## 2.梯度下降

是一种迭代优化算法，用于最小化损失函数。

它通过计算损失函数对参数的导数（梯度），沿着梯度的反方向更新参数。

## 3.学习率

过大：

- 更新步长太大，可能导致损失函数震荡甚至发散。

- 模型无法收敛，训练失败。

过小：

- 更新步长太小，收敛速度慢。

- 训练时间长，可能陷入局部最优。

## 4.梯度下降 vs 随机梯度下降（SGD）

方法                           描述             优点           缺点
梯度下降（GD）    每次使用全部数据计算一次梯度    稳定收敛        每次计算代价高
随机梯度下降（SGD）    每次只用一个样本更新    快速、低成本    波动大、不稳定

# 四、基于Pytorch的线性回归实现

## 1.miniconda +Pytorch

学会了配置虚拟环境，并使用
同时下载了jupyter notebook

我使用的是Pycharm，在安装拍torch插件的时候，无法下载

通过官网链接下载非常慢，下载半小时还是失败

后通过stfw，用清华镜像源成功下载，但是速度特别慢，只有1mb/s

同时也学会了一些基本的命令行命令、conda的指令

## 2.线性回归

### 一、什么是线性回归？

线性回归是**监督学习中最基础的预测算法**，核心假设是**输入特征与输出变量之间存在线性关系**。它通过拟合一条最优的直线（或超平面），将输入特征映射到连续型输出值，目标是最小化预测值与真实值之间的误差。  

- **数学模型**：  
  对于输入特征 $X$（单个或多个），预测输出 $\hat{y}$ 的公式为：  
  
  - 一元线性回归：$\hat{y} = w \cdot x + b$（$w$=权重，$b$=偏置）  
  - 多元线性回归：$\hat{y} = w_1x_1 + w_2x_2 + ... + w_nx_n + b$（$n$=特征数量）  

- **优化目标**：  
  使用**均方误差（MSE）**作为损失函数，衡量预测误差：  
  $Loss = \frac{1}{N}\sum_{i=1}^N (\hat{y_i} - y_i)^2$  
  通过**梯度下降**等方法更新 $w$ 和 $b$，使损失函数最小化。  

### 二、线性回归解决什么问题？

线性回归用于**预测连续型输出变量**，典型场景包括：  

- 房价预测（输入：面积、房间数 → 输出：房价）  
- 销量预测（输入：广告投入、促销活动 → 输出：商品销量）  
- 温度预测（输入：历史气温、湿度 → 输出：明日气温）  
- 医疗指标预测（输入：年龄、血压 → 输出：血糖值）  

### 三、一元与多元线性回归的区别

| **维度** | **一元线性回归**           | **多元线性回归**                          |
| ------ | -------------------- | ----------------------------------- |
| 特征数量   | 仅1个输入特征（$x$）         | 多个输入特征（$x_1, x_2, ...x_n$）          |
| 模型形式   | $\hat{y}=wx + b$（直线） | $\hat{y}=w_1x_1+...+w_nx_n +b$（超平面） |
| 适用场景   | 单一因素影响输出（如温度→冰淇淋销量）  | 多因素共同影响输出（温度+促销+天气→冰淇淋销量）           |
| 拟合复杂度  | 简单，易解释               | 较复杂，但能捕捉更多变量间的关系                    |

### 四、机器学习其他经典问题类型

除回归外，机器学习还有以下核心问题类型：  

#### 1. **分类问题**

- **目标**：预测离散型输出（类别标签）。  
- **例子**：垃圾邮件识别（垃圾/非垃圾）、图像分类（猫/狗）、疾病诊断（患病/健康）。  
- **常用算法**：逻辑回归、SVM、决策树、随机森林、CNN（图像分类）。  

#### 2. **聚类问题**

- **目标**：无监督学习，将相似数据自动分组（无标签）。  
- **例子**：用户分群（根据购买行为分群体）、新闻主题聚类、图像相似性聚类。  
- **常用算法**：K-means、DBSCAN、层次聚类。  

#### 3. **降维问题**

- **目标**：减少特征维度，保留关键信息（降低计算成本、避免过拟合）。  
- **例子**：高维图像压缩（PCA）、特征选择（过滤/包裹法）。  
- **常用算法**：PCA（主成分分析）、t-SNE（可视化高维数据）、AutoEncoder。  

#### 4. **生成式问题**

- **目标**：生成与训练数据相似的新数据。  
- **例子**：GAN生成逼真人脸、VAE生成文本/图像、GPT生成自然语言。  
- **常用算法**：GAN、VAE、Transformer（如GPT系列）。  

#### 5. **强化学习问题**

- **目标**：智能体通过与环境交互，学习最优策略以最大化奖励。  
- **例子**：AlphaGo下棋、自动驾驶决策、机器人导航。  
- **常用算法**：Q-learning、DQN、PPO。  

#### 6. **序列预测问题**

- **目标**：处理时序/序列数据，预测下一个元素或序列。  
- **例子**：股票走势预测、机器翻译（文本序列→文本序列）、语音识别（音频序列→文字序列）。  
- **常用算法**：RNN、LSTM、Transformer（如BERT、GPT）。